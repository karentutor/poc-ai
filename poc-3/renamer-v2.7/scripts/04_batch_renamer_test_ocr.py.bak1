#!/usr/bin/env python
# 03_rename_from_index.py
import fitz, faiss, pickle, argparse, json, sys, os, glob, io
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import torch
import time
import csv  # Add csv module for proper CSV handling
from scipy.spatial.distance import cosine, euclidean
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re

# OCR dependencies - optional
try:
    import pytesseract
    from PIL import Image
    import cv2
    OCR_AVAILABLE = True
    # Try to set the tesseract command path if it's not found by default
    try:
        pytesseract.get_tesseract_version()
    except Exception as e:
        # Check if we're in a conda environment
        conda_prefix = os.environ.get('CONDA_PREFIX')
        if conda_prefix:
            # Try to set the path to tesseract in the conda environment
            tesseract_path = os.path.join(conda_prefix, 'bin', 'tesseract')
            if os.path.exists(tesseract_path):
                pytesseract.pytesseract.tesseract_cmd = tesseract_path
                tqdm.write(f"Set tesseract path to: {tesseract_path}")
                
        # If on Windows, try the default installation path
        if sys.platform.startswith('win'):
            program_files = os.environ.get('PROGRAMFILES', 'C:\\Program Files')
            tesseract_path = os.path.join(program_files, 'Tesseract-OCR', 'tesseract.exe')
            if os.path.exists(tesseract_path):
                pytesseract.pytesseract.tesseract_cmd = tesseract_path
                tqdm.write(f"Set tesseract path to: {tesseract_path}")
except ImportError:
    OCR_AVAILABLE = False
    tqdm.write("OCR dependencies not available. Install with: pip install pytesseract pillow opencv-python")

MODEL = "sentence-transformers/all-MiniLM-L6-v2"
MARGIN = 50  # Increased from 30 to capture more context
OCR_DPI = 300  # DPI for OCR processing
MAX_WORDS = 40  # Increased from 25 to allow more context
OCR_LANG = "eng"  # Default OCR language

# Available similarity metrics
SIMILARITY_METRICS = {
    "cosine": lambda x, y: 1 - cosine(x, y),  # Cosine similarity (default)
    "euclidean": lambda x, y: 1 / (1 + euclidean(x, y)),  # Normalized Euclidean distance
    "dot": lambda x, y: np.dot(x, y),  # Dot product
    "cosine_sklearn": lambda x, y: cosine_similarity([x], [y])[0][0]  # sklearn's cosine similarity
}

# Default thresholds for different metrics
DEFAULT_THRESHOLDS = {
    "cosine": 0.7,  # Higher is better
    "euclidean": 0.3,  # Higher is better
    "dot": 0.5,  # Higher is better
    "cosine_sklearn": 0.7  # Higher is better
}

def load_index(prefix="widget"):
    try:
        # Load the index and metadata
        index_obj = faiss.read_index(f"{prefix}.faiss")
        metadata = pickle.load(open(f"{prefix}_metadata.pkl", "rb"))
        
        # Load configuration
        config_filename = f"{prefix}_config.json"
        try:
            with open(config_filename, "r") as cf:
                config = json.load(cf)
            model_name = config.get("model", MODEL)
        except Exception as e:
            tqdm.write(f"No config for {prefix} or error loading config: {e}. Using default model.")
            model_name = MODEL
            
        return index_obj, metadata, model_name
    except (FileNotFoundError, IOError) as e:
        tqdm.write(f"Warning: Could not load index {prefix}: {e}")
        return None, None, None

def load_all_indexes(gpu=False):
    # Check if GPU is available when requested
    device = None
    if gpu:
        if torch.cuda.is_available():
            device = "cuda"
            tqdm.write(f"Using GPU: {torch.cuda.get_device_name(0)}")
        else:
            tqdm.write("GPU requested but not available, falling back to CPU")
            device = "cpu"
    else:
        device = "cpu"
        tqdm.write("Using CPU for processing")

    # Global embedder as fallback
    embedder = SentenceTransformer(MODEL, device=device)
    
    # Automatically load all indexes by scanning for files ending with '.faiss'
    faiss_files = glob.glob("*.faiss")
    loaded_indexes = []
    for faiss_file in faiss_files:
        prefix = faiss_file[:-6]  # Remove the '.faiss' extension
        index_obj, metadata, model_name = load_index(prefix)
        if index_obj is not None:
            # Create embedder for this index
            try:
                embedder_for_index = SentenceTransformer(model_name, device=device)
            except Exception as e:
                tqdm.write(f"Error loading model {model_name} for {prefix}, using default: {e}")
                embedder_for_index = embedder
                
            # Configure GPU resources for FAISS if available and requested
            if gpu and device == "cuda":
                try:
                    # Try to move the index to GPU if supported by the index type
                    if hasattr(index_obj, 'getDevices') and index_obj.ntotal > 0:
                        res = faiss.StandardGpuResources()
                        index_obj = faiss.index_cpu_to_gpu(res, 0, index_obj)
                        tqdm.write(f"Successfully moved index {prefix} to GPU")
                except Exception as e:
                    tqdm.write(f"Could not move index {prefix} to GPU: {str(e)}")
                    
            loaded_indexes.append((prefix, index_obj, metadata, embedder_for_index))
    
    if not loaded_indexes:
        tqdm.write("Error: No valid indexes could be loaded. Exiting.")
        return None, None
        
    return loaded_indexes, device

def ocr_text(page, rect, dpi=OCR_DPI):
    """Extract text from image using OCR with enhanced preprocessing."""
    if not OCR_AVAILABLE:
        return ""
    
    zoom = dpi / 72
    matrix = fitz.Matrix(zoom, zoom)
    
    # Ensure the rectangle is valid
    if rect.is_empty or rect.is_infinite:
        # Use the entire page if rect is invalid
        rect = page.rect
    
    # Create a pixmap for the specified area
    try:
        pix = page.get_pixmap(matrix=matrix, clip=rect)
        img_data = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        
        # Convert to grayscale and preprocess for better OCR
        gray = np.array(img.convert('L'))
        
        # Enhanced preprocessing for better OCR results
        try:
            # 1. Apply contrast enhancement
            # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(gray)
            
            # 2. Noise reduction
            denoised = cv2.fastNlMeansDenoising(enhanced, None, 10, 7, 21)
            
            # 3. Adaptive threshold with different parameters
            binary = cv2.adaptiveThreshold(
                denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 8
            )
            
            # 4. Try different Tesseract configurations
            # PSM modes: 1=Auto with OSD, 3=Auto, 4=Single column, 6=Single block, 11=Single line
            text = pytesseract.image_to_string(
                binary, 
                config=f'--psm 6 --oem 3 -l {OCR_LANG}',
                lang=OCR_LANG
            )
            
            # If text is empty or very short, try with original enhanced image
            if len(text.strip()) < 5:
                text = pytesseract.image_to_string(
                    enhanced, 
                    config=f'--psm 4 --oem 3 -l {OCR_LANG}',
                    lang=OCR_LANG
                )
            
            # If still short, try one more approach with different parameters    
            if len(text.strip()) < 5:
                # Try another preprocessing approach - inverse binary threshold
                _, binary_inv = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
                text = pytesseract.image_to_string(
                    binary_inv, 
                    config=f'--psm 11 --oem 3 -l {OCR_LANG}',
                    lang=OCR_LANG
                )
                
        except Exception as inner_e:
            try:
                # Fallback 1: Try direct OCR on grayscale without preprocessing
                text = pytesseract.image_to_string(gray, config=f'--psm 6 -l {OCR_LANG}')
            except Exception as inner_e2:
                try:
                    # Fallback 2: Save to temp file and try direct command
                    import tempfile
                    import subprocess
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                        tmp_path = tmp.name
                        cv2.imwrite(tmp_path, gray)
                    
                    # Get tesseract command path
                    tesseract_cmd = pytesseract.pytesseract.tesseract_cmd or 'tesseract'
                    output_base = tmp_path + "_out"
                    
                    # Run tesseract directly
                    result = subprocess.run(
                        [tesseract_cmd, tmp_path, output_base, "--psm", "6", "-l", OCR_LANG], 
                        capture_output=True, 
                        text=True
                    )
                    
                    if result.returncode == 0:
                        # Read the output file
                        with open(output_base + ".txt", "r") as f:
                            text = f.read().strip()
                        # Clean up temporary files
                        os.remove(tmp_path)
                        os.remove(output_base + ".txt")
                    else:
                        text = ""
                except Exception:
                    text = ""
        
        # Post-process OCR text: clean up common OCR errors
        if text:
            # Remove excessive whitespace
            text = re.sub(r'\s+', ' ', text).strip()
            
            # Replace common OCR errors
            replacements = {
                '|': 'I',          # Pipe to I
                '{}': '()',        # Braces to parentheses
                '[]': '()',        # Brackets to parentheses
                'l1': 'h',         # Common error
                'rn': 'm',         # Common error
                'm': 'rn',         # Reverse common error for form context
                '0O': 'O',         # Zero to O
                '1I': 'I',         # One to I
                '5S': 'S',         # Five to S
                'ii': 'n',         # Double i to n
                'cl': 'd',         # cl to d
                'nn': 'm',         # Double n to m
            }
            
            for error, correction in replacements.items():
                for e in error:
                    for c in correction:
                        text = text.replace(e, c)
            
            # Process PDF form specific text errors
            form_replacements = {
                'Pmimcipah': 'Principal',
                'Sumety': 'Surety',
                'bomd': 'bond',
                'dohham': 'dollar',
                'Lamdhomd': 'Landlord',
                'Sigmatum': 'Signature',
                'Imsumamc': 'Insurance',
                'Comtmact': 'Contract',
                'Compamy': 'Company',
                'tmuhy': 'truly',
                'fimmhy': 'firmly',
                'boumd': 'bound',
                'umto': 'unto',
                'Agemt': 'Agent',
                'Obligatiom': 'Obligation',
                'Comditiom': 'Condition',
                'Attommey': 'Attorney',
                'Fact': 'Fact',
                'Witmess': 'Witness',
                'Licensimg': 'Licensing',
                'Commissiom': 'Commission',
                'underpimmed': 'undersigned',
                'umdersigned': 'undersigned',
                'pomatiom': 'poration',
                'Compomatiom': 'Corporation',
                'Wammamt': 'Warrant',
                'Guamamtee': 'Guarantee',
                'Pemformamce': 'Performance',
                'Paymemt': 'Payment',
                'Signatum': 'Signature',
                'Ackmowledgememt': 'Acknowledgement',
                'hemeby': 'hereby',
                'hemein': 'herein',
                'hemeumto': 'hereunto',
                'hemeof': 'hereof',
                'themsehves': 'themselves',
                'acknowhedge': 'acknowledge',
                'obhigatiom': 'obligation',
                'obhigor': 'obligor',
                'obhigee': 'obligee',
                'COMTRACTOR': 'CONTRACTOR',
                'MAIMT': 'MAINT',
                'MAIM': 'MAIN',
                'BOMD': 'BOND',
                'PAYMEMT': 'PAYMENT',
                'PEMFORMAMCE': 'PERFORMANCE',
                'COMSTRUCTIOM': 'CONSTRUCTION'
            }
            
            # Additional case-insensitive replacements for word parts
            partial_replacements = {
                'mce': 'nce',
                'mcip': 'ncip',
                'mder': 'nder',
                'mamce': 'nance',
                'mamt': 'nant',
                'tmer': 'tner',
                'mom': 'non',
                'moti': 'noti',
                'imd': 'ind',
                'amd': 'and',
                'ahh': 'all',
                'amm': 'ann',
                'ome': 'one',
                'bem': 'ben',
                'emt': 'ent',
                'amt': 'ant'
            }
            
            for error, correction in form_replacements.items():
                text = text.replace(error, correction)
            
            # Apply partial replacements more carefully
            for error, correction in partial_replacements.items():
                # Only replace when likely part of a word, not a whole word
                text = re.sub(r'\b\w*' + error + r'\w*\b', 
                             lambda m: m.group(0).replace(error, correction), 
                             text)
            
            # Limit context length similar to the original script
            words = text.split()
            if len(words) > MAX_WORDS:
                text = ' '.join(words[:MAX_WORDS])
        
        return text.strip()
    except Exception as e:
        error_msg = str(e)
        if "libarchive.so" in error_msg:
            tqdm.write("\n⚠️ Missing libarchive dependency. For Conda environments: conda install -c conda-forge libarchive")
        return ""

def surrounding_text(page, rect, use_ocr=True):
    """Extract text around a widget with optional OCR support."""
    words = page.get_text("words")
    filtered_words = [w for w in words if fitz.Rect(w[:4]).intersects(rect)]
    
    # If no text found and OCR is enabled, try OCR
    if not filtered_words and use_ocr and OCR_AVAILABLE:
        ocr_result = ocr_text(page, rect)
        if ocr_result:
            return ocr_result
    
    # Return standard text extraction result
    return " ".join(w[4] for w in filtered_words)

def propose_names(pdf_in, loaded_indexes, device, k=1, threshold=None, similarity_metric="cosine", use_ocr=True):
    start_time = time.time()
    
    # Set default threshold based on similarity metric if not provided
    if threshold is None:
        threshold = DEFAULT_THRESHOLDS[similarity_metric]
    
    # Create reports directory if it doesn't exist
    reports_dir = "reports"
    if not os.path.exists(reports_dir):
        os.makedirs(reports_dir)
    
    # Get the base filename without extension
    base_name = os.path.splitext(os.path.basename(pdf_in))[0]
    report_csv_path = os.path.join(reports_dir, f"{base_name}.csv")
    
    doc, mapping = fitz.open(pdf_in), {}
    total_counter = 0
    same_counter = 0
    index_usage_counts = {prefix: 0 for prefix, _, _, _ in loaded_indexes}
    
    with open(report_csv_path, 'w', newline='') as report_csv:
        writer = csv.writer(report_csv, quoting=csv.QUOTE_ALL)  # Quote all fields
        writer.writerow(["current_name", "proposed_name", "confidence", "index_used", "context_match", "document_name", "section_context"])
        
        for page in doc:
            for w in page.widgets():
                current_name = w.field_name
                ctx = surrounding_text(
                    page,
                    fitz.Rect(w.rect.x0-MARGIN, w.rect.y0-MARGIN,
                              w.rect.x1+MARGIN, w.rect.y1+MARGIN),
                    use_ocr=use_ocr
                )
                if not ctx.strip():
                    continue
                
                best_score = float('-inf')  # Initialize with negative infinity for similarity scores
                best_name = None
                best_index = None
                best_metadata = None
                
                # Iterate through each index and generate a query vector using its specific embedder
                for prefix, index_obj, metadata, index_embedder in loaded_indexes:
                    q_vec = index_embedder.encode([ctx], convert_to_numpy=True).astype("float32")
                    # Check if query vector dimension matches the index dimension
                    if q_vec.shape[1] != index_obj.d:
                        tqdm.write(f"Skipping index {prefix}: Query vector dimension {q_vec.shape[1]} does not match index dimension {index_obj.d}")
                        continue
                    
                    # Get the nearest neighbors
                    distances, idx = index_obj.search(q_vec, k)
                    
                    # Calculate similarity score based on the chosen metric
                    if similarity_metric == "euclidean":
                        # For Euclidean, we need to convert distance to similarity
                        score = 1 / (1 + distances[0][0])
                    else:
                        # For other metrics, we use the distance directly
                        score = distances[0][0]
                    
                    if score > best_score:  # Higher score is better for all metrics
                        best_score = score
                        best_metadata = metadata[idx[0][0]]
                        best_name = best_metadata["widgetName"]
                        best_index = prefix
                
                if best_name is None:
                    best_name = current_name
                    best_score = float('-inf')
                    best_index = "None"
                    best_metadata = {"context": "", "documentName": "", "sectionContext": []}
                if best_index not in index_usage_counts:
                    index_usage_counts[best_index] = 0
                
                # Update the usage count for the selected index
                index_usage_counts[best_index] += 1
                
                # Append score if below threshold (for all metrics, higher score is better)
                if best_score < threshold:
                    mapping[w.field_name] = f"{best_name}_{best_score:.2f}"
                else:
                    mapping[w.field_name] = best_name
                
                total_counter += 1
                if current_name == mapping[w.field_name]:
                    same_counter += 1
                
                # Format section context for CSV
                section_context = "; ".join([f"{s['text']} (p.{s['page']})" for s in best_metadata.get("sectionContext", [])])
                
                writer.writerow([
                    current_name, 
                    mapping[w.field_name], 
                    f"{best_score:.4f}", 
                    best_index, 
                    best_metadata.get("context", ""),
                    best_metadata.get("documentName", ""),
                    section_context
                ])
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    if total_counter > 0:
        percent_same = (same_counter / total_counter) * 100
        rounded_percent_same = round(percent_same, 2)
        
        # Create index usage summary
        index_usage_summary = ", ".join([f"{prefix}: {count}" for prefix, count in index_usage_counts.items()])
        
        tqdm.write(f"PDF: {base_name}.pdf Accuracy: {rounded_percent_same}% Fields: {same_counter} out of {total_counter}")
        tqdm.write(f"Index usage: {index_usage_summary}")
        tqdm.write(f"Processing time: {processing_time:.2f} seconds")
        tqdm.write(f"Using similarity metric: {similarity_metric} with threshold: {threshold}")
        tqdm.write("")  # Add an empty line between PDF processing logs
    else:
        tqdm.write(f"PDF: {base_name}.pdf Accuracy: 0% Fields: {same_counter} out of {total_counter}")
        tqdm.write("")  # Add an empty line between PDF processing logs
    doc.close()

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--folder_in", required=True, help="Folder containing PDFs to process")
    ap.add_argument("--idx", help="Deprecated. This argument is ignored since indexes are auto-loaded.", default="widget")
    ap.add_argument("-k", type=int, default=1, help="Number of nearest neighbors to retrieve")
    ap.add_argument("--threshold", type=float, help="Similarity threshold (higher is better)")
    ap.add_argument("--similarity", default="cosine", choices=list(SIMILARITY_METRICS.keys()),
                    help="Similarity metric to use (cosine, euclidean, dot, cosine_sklearn)")
    ap.add_argument("--dry", action="store_true", help="Just print mapping without saving")
    ap.add_argument("--gpu", action="store_true", help="Use GPU acceleration if available", default=True)
    ap.add_argument("--skip-existing", action="store_true", help="Skip PDFs that already have reports")
    ap.add_argument("--ocr", action="store_true", help="Enable OCR for scanned documents", default=False)
    ap.add_argument("--ocr-lang", default="eng", help="OCR language (default: eng, use +eng for multiple languages)")
    args = ap.parse_args()

    # Set OCR language if specified
    if args.ocr_lang:
        OCR_LANG = args.ocr_lang

    # Show OCR status
    if args.ocr:
        if OCR_AVAILABLE:
            tqdm.write("🔍 OCR support is enabled for scanned documents")
        else:
            tqdm.write("⚠️ OCR was requested but dependencies are not available")
            tqdm.write("⚠️ Install with: pip install pytesseract pillow opencv-python")
            args.ocr = False

    # Get list of PDF files and sort them numerically
    pdf_files = [f for f in os.listdir(args.folder_in) if f.lower().endswith('.pdf')]
    
    def natural_sort_key(filename):
        # Split the filename into text and numeric parts
        parts = re.split(r'(\d+)', os.path.splitext(filename)[0])
        # Return a list with string parts as-is and numeric parts converted to int
        return [int(part) if part.isdigit() else part.lower() for part in parts]
    
    pdf_files.sort(key=natural_sort_key)
    
    # Create reports directory if it doesn't exist
    reports_dir = "reports"
    if not os.path.exists(reports_dir):
        os.makedirs(reports_dir)
    
    # Filter out PDFs that already have reports if skip-existing is enabled
    if args.skip_existing:
        pdf_files = [
            pdf for pdf in pdf_files 
            if not os.path.exists(os.path.join(reports_dir, f"{os.path.splitext(pdf)[0]}.csv"))
        ]
        if not pdf_files:
            print("All PDFs already have reports. Nothing to process.")
            sys.exit(0)
    
    # Load all indexes once before processing PDFs
    loaded_indexes, device = load_all_indexes(args.gpu)
    if loaded_indexes is None:
        sys.exit(1)
    
    # Process files with progress bar
    for pdf in tqdm(pdf_files, desc="Processing PDFs"):
        pdf_in = os.path.join(args.folder_in, pdf)
        propose_names(pdf_in, loaded_indexes, device, args.k, args.threshold, args.similarity, use_ocr=args.ocr)
